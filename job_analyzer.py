import streamlit as st
import os
import re
import requests
import pandas as pd
from bs4 import BeautifulSoup
from typing import List, Optional, Literal
from pydantic import BaseModel, Field
import instructor
from groq import Groq
from dotenv import load_dotenv

# ==============================================================================
# 1. SETUP & SECURITATE
# ==============================================================================
st.set_page_config(page_title="GenAI Headhunter", page_icon="üïµÔ∏è", layout="wide")

# √éncƒÉrcƒÉm variabilele din fi»ôierul .env
load_dotenv()

# √éncercƒÉm sƒÉ luƒÉm cheia din OS (local) sau din Streamlit Secrets (cloud)
api_key = os.getenv("GROQ_API_KEY")

# Fallback pentru Streamlit Cloud deployment
if not api_key and "GROQ_API_KEY" in st.secrets:
    api_key = st.secrets["GROQ_API_KEY"]

# Validare criticƒÉ: DacƒÉ nu avem cheie, oprim aplica»õia aici.
if not api_key:
    st.error("‚õî EROARE CRITICƒÇ: Lipse»ôte `GROQ_API_KEY`.")
    st.info("Te rog creeazƒÉ un fi»ôier `.env` √Æn folderul proiectului »ôi adaugƒÉ: GROQ_API_KEY=cheia_ta_aici")
    st.stop()

# Configurare Client Groq Global (pentru a nu-l reini»õializa constant)
client = instructor.from_groq(Groq(api_key=api_key), mode=instructor.Mode.TOOLS)

# Sidebar Informativ (FƒÉrƒÉ input de date sensibile)
with st.sidebar:
    st.header("üïµÔ∏è GenAI Headhunter")
    st.success("‚úÖ API Key √ÆncƒÉrcat securizat")
    st.markdown("---")
    st.write("Acest tool demonstreazƒÉ:")
    st.write("‚Ä¢ Web Scraping (BS4)")
    st.write("‚Ä¢ Secure Env Variables")
    st.write("‚Ä¢ Structured Data (Pydantic)")


# ==============================================================================
# 2. DATA MODELS (PYDANTIC SCHEMAS)
# ==============================================================================
from typing import List, Optional, Literal
from pydantic import BaseModel, Field, model_validator


class SalaryRange(BaseModel):
    min: int = Field(..., ge=0, description="Salariul minim")
    max: int = Field(..., ge=0, description="Salariul maxim")
    currency: str = Field(..., description="Moneda (EUR, USD, RON etc.)")

    @model_validator(mode="after")
    def check_range(self):
        if self.max < self.min:
            raise ValueError("Salary max nu poate fi mai mic dec√¢t min.")
        return self


class Location(BaseModel):
    city: str = Field(..., description="Ora»ôul jobului")
    country: str = Field(..., description="»öara jobului")
    is_remote: bool = Field(False, description="True dacƒÉ jobul este remote sau hibrid")


class RedFlag(BaseModel):
    severity: Literal["low", "medium", "high"] = Field(
        ..., description="Nivel gravitate"
    )
    category: Literal["toxicity", "vague", "unrealistic"] = Field(
        ..., description="Categoria problemei"
    )
    description: str = Field(..., description="Descriere scurtƒÉ")


class JobAnalysis(BaseModel):
    role_title: str
    company_name: str

    seniority: Literal["Intern", "Junior", "Mid", "Senior", "Lead", "Architect"]

    match_score: int = Field(..., ge=0, le=100)

    tech_stack: List[str]

    salary_range: Optional[SalaryRange] = None
    location: Optional[Location] = None

    red_flags: List[RedFlag] = Field(default_factory=list)

    summary: str

    @model_validator(mode="after")
    def validate_remote_consistency(self):
        """
        DacƒÉ jobul e remote, dar apar indicii cƒÉ e necesarƒÉ prezen»õa fizicƒÉ,
        adƒÉugƒÉm automat un red flag.
        """

        if self.location and self.location.is_remote:
            office_keywords = ["on-site", "office presence", "la birou", "prezen»õƒÉ fizicƒÉ"]

            for flag in self.red_flags:
                if any(keyword in flag.description.lower() for keyword in office_keywords):
                    self.red_flags.append(
                        RedFlag(
                            severity="medium",
                            category="unrealistic",
                            description="Job marcat remote, dar descrierea sugereazƒÉ prezen»õƒÉ fizicƒÉ."
                        )
                    )
                    break

        return self

# ==============================================================================
# 3. UTILS - SCRAPER (Colectare Date)
# ==============================================================================

def scrape_clean_job_text(url: str, max_chars: int = 3000) -> str:
    """
    DescarcƒÉ pagina »ôi returneazƒÉ un text curat, optimizat pentru contextul LLM.
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200:
            return f"Error: Status code {response.status_code}"
            
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # EliminƒÉm elementele inutile care consumƒÉ tokeni
        for junk in soup(["script", "style", "nav", "footer", "header", "aside", "iframe"]):
            junk.decompose()
            
        # Extragem textul »ôi eliminƒÉm spa»õiile multiple
        text = soup.get_text(separator=' ', strip=True)
        text = re.sub(r'\s+', ' ', text)
        
        return text[:max_chars] 
        
    except Exception as e:
        return f"Scraping Error: {str(e)}"

# ==============================================================================
# 4. AI SERVICE LAYER (Logica LLM)
# ==============================================================================

def analyze_job_with_ai(text: str) -> JobAnalysis:
    """
    Trimite textul curƒÉ»õat cƒÉtre Groq »ôi returneazƒÉ obiectul structurat.
    """
    return client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        response_model=JobAnalysis,
        messages=[
            {
                "role": "system", 
                "content": (
                    "E»ôti un Recruiter Expert √Æn IT. AnalizeazƒÉ textul jobului cu obiectivitate. "
                    "IdentificƒÉ tehnologiile »ôi poten»õialele probleme (red flags). "
                    "RƒÉspunde strict √Æn formatul cerut."
                )
            },
            {
                "role": "user", 
                "content": f"AnalizeazƒÉ acest job description:\n\n{text}"
            }
        ],
        temperature=0.1,
    )

# ==============================================================================
# 5. UI - APLICA»öIA STREAMLIT
# ==============================================================================

st.title("üïµÔ∏è GenAI Headhunter Assistant")
st.markdown("TransformƒÉ orice Job Description √Æntr-o analizƒÉ structuratƒÉ folosind AI.")

# Tab-uri
tab1, tab2 = st.tabs(["üöÄ AnalizƒÉ Job", "üìä Market Scan (Batch)"])

# --- TAB 1: ANALIZA UNUI SINGUR LINK ---
with tab1:
    st.subheader("AnalizeazƒÉ un Job URL")
    url_input = st.text_input("Introdu URL-ul:", placeholder="https://...")
    
    if st.button("AnalizeazƒÉ Job", key="btn_single"):
        if not url_input:
            st.warning("Te rugƒÉm introdu un URL.")
        else:
            with st.spinner("üï∑Ô∏è Scraping & ü§ñ AI Analysis..."):
                raw_text = scrape_clean_job_text(url_input)
            
            if "Error" in raw_text:
                st.error(raw_text)
            else:
                try:
                    data = analyze_job_with_ai(raw_text)
                    
                    # -- DISPLAY --
                    st.divider()

                    # ===============================
                    # HEADER SECTION
                    # ===============================
                    col_h1, col_h2 = st.columns([3, 1])

                    with col_h1:
                        st.markdown(f"## {data.role_title}")
                        st.caption(f"üè¢ {data.company_name} ‚Ä¢ üéØ {data.seniority}")

                    with col_h2:
                        score_color = "normal" if data.match_score >= 75 else "inverse"
                        st.metric("Quality Score", f"{data.match_score}/100", delta_color=score_color)

                    # ===============================
                    # QUICK STATS ROW
                    # ===============================
                    city = data.location.city if data.location else "Nespecificat"
                    country = data.location.country if data.location else ""
                    is_remote = data.location.is_remote if data.location else False

                    salary_text = "Nespecificat"
                    if data.salary_range:
                        salary_text = f"{data.salary_range.min}-{data.salary_range.max} {data.salary_range.currency}"

                    c1, c2, c3, c4 = st.columns(4)

                    c1.info(f"üìç **Loca»õie:** {city} {country}")
                    c2.info(f"üè† **Remote:** {'Da' if is_remote else 'Nu'}")
                    c3.success(f"üõ†Ô∏è **Tehnologii:** {len(data.tech_stack)}")
                    c4.warning(f"üö© **Red Flags:** {len(data.red_flags)}")

                    # ===============================
                    # SALARY SECTION
                    # ===============================
                    st.markdown("### üí∞ Salary")
                    if data.salary_range:
                        st.success(f"Interval salarial: **{salary_text}**")
                    else:
                        st.caption("Nu este specificat un interval salarial.")

                    # ===============================
                    # SUMMARY SECTION
                    # ===============================
                    st.markdown("### üìù Rezumat")
                    st.info(data.summary)

                    # ===============================
                    # TECH STACK SECTION
                    # ===============================
                    st.markdown("### üõ†Ô∏è Tech Stack")

                    if data.tech_stack:
                        tech_badges = " ".join([f"`{tech}`" for tech in data.tech_stack])
                        st.markdown(tech_badges)
                    else:
                        st.caption("Nu au fost identificate tehnologii clare.")

                    # ===============================
                    # RED FLAGS SECTION
                    # ===============================
                    st.markdown("### üö© Avertismente")

                    if data.red_flags:
                        for flag in data.red_flags:
                            label = f"[{flag.severity.upper()} | {flag.category.upper()}]"
                            
                            if flag.severity == "high":
                                st.error(f"{label} {flag.description}")
                            elif flag.severity == "medium":
                                st.warning(f"{label} {flag.description}")
                            else:
                                st.info(f"{label} {flag.description}")
                    else:
                        st.success("Nu au fost detectate red flags majore.")

                except Exception as e:
                    st.error(f"Eroare AI: {str(e)}")

# --- TAB 2: BATCH PROCESSING ---
with tab2:
    st.subheader("üìä ComparƒÉ mai multe joburi")
    urls_text = st.text_area("Paste URL-uri (unul pe linie):", height=150)
    
    if st.button("ScaneazƒÉ Pia»õa", key="btn_batch"):
        urls = [u.strip() for u in urls_text.split('\n') if u.strip()]
        
        if not urls:
            st.warning("Nu ai introdus link-uri.")
        else:
            results = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, link in enumerate(urls):
                status_text.text(f"Analizez {i+1}/{len(urls)}...")
                text = scrape_clean_job_text(link)
                
                if "Error" not in text:
                    try:
                        res = analyze_job_with_ai(text)
                        results.append({
                            "Role": res.role_title,
                            "Company": res.company_name,
                            "Seniority": res.seniority,
                            "Tech": res.tech_stack,
                            "Score": res.match_score
                        })
                    except:
                        pass # ContinuƒÉm chiar dacƒÉ unul crapƒÉ
                
                progress_bar.progress((i + 1) / len(urls))
            
            status_text.text("Gata!")
            
            if results:
                df = pd.DataFrame(results)
                st.dataframe(df)
                
                # Grafic simplu
                st.bar_chart(df['Seniority'].value_counts())